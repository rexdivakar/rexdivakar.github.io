[ { "title": "A beginner‚Äôs guide to Docker‚Ää ‚Äî‚Ää How to create your first Docker application üê≥", "url": "/posts/docker_onboarding/", "categories": "containers, docker", "tags": "docker, docker-compose, containers", "date": "2022-06-07 13:17:00 +0530", "snippet": "Now let‚Äôs create your first applicationBefore starting to build the app, let‚Äôs first install the pre-requisites that are required for building the docker containers,1. Install Docker on your machine For Linux (Ubuntu/Debian Based distros):sudo apt install docker.ioFor MacOSX: you can follow this link For Windows: you can follow this link For Windows (Enable WSL2 backend for optimized performance)Finally, verify that Docker is installed correctlysudo docker run hello-world2. Create your projectCreate a new directory and two files main.py and Dockerfile. main.py ‚Äì contains python code for web server. Dockerfile ‚Äì this file contains the structure of container. requirements.txt ‚Äì this is a dependency file for python web server(flask).Kindly add this code to your main.py to initiate web server,from flask import Flaskapp = Flask(__name__)@app.route('/')def hello_world(): return 'Hello World'if __name__ == '__main__': app.run(debug=True, host='0.0.0.0', port=5000)add the below dependency to requirements.txt file,Flask==2.1.23. Edit the Docker fileThe first step to take when you create a Docker file is to access the DockerHub website. This site contains many pre-designed images to save your time (for example: all images for linux or code languages).In our case, we will type ‚ÄòPython‚Äô in the search bar. The first result is the official image created to execute Python. Perfect, we‚Äôll use it!# start by pulling the python imageFROM python:3.8-alpine# copy every content from the local file to the imageCOPY . /app# switch working directoryWORKDIR /app# install the dependencies and packages in the requirements fileRUN pip install -r /app/requirements.txt# run the python codeCMD [\"python\", \"main.py\" ]Let‚Äôs go over the instructions in this DockerfileFROM python:3.8-alpine: Since Docker allows us to inherit existing images, we install a Python image and install it in our Docker image. Alpine is a lightweight Linux distro that will serve as the OS on which we install our imageCOPY ./requirements.txt /app/requirements.txt: Here, we copy the requirements file and its content (the generated packages and dependencies) into the app folder of the imageWORKDIR /app: We proceed to set the working directory as /app, which will be the root directory of our application in the containerRUN pip install -r requirements.txt: This command installs all the dependencies defined in the requirements.txt file into our application within the containerCOPY . /app: This copies every other file and its respective contents into the app folder that is the root directory of our application within the containerENTRYPOINT [ ‚Äúpython‚Äù ]: This is the command that runs the application in the containerCMD [ ‚Äúmain.py‚Äù ]: Finally, this appends the list of parameters to the EntryPoint parameter to perform the command that runs the application. This is similar to how you would run the Python app on your terminal using the python main.py command.4. Build the Docker imageLet‚Äôs proceed to build the image with the command below:docker image build -t flask_docker .5. Run the containerAfter successfully building the image, the next step is to run an instance of the image. Here is how to perform this:docker run -p 5000:5000 -d --name new_app flask_dockerThis command deploys the container with the python flask server running on port 5000, Here is the output of our application when we send a request to localhost:5000 on our browser,Track the container statusThe below command displays the list of all running active containers, check if your deployed container is in running status!docker ps -a6. Useful commands for Docker List your imagesdocker images Delete a specific imagedocker image rm [image name] List all existing containers (running and not running)docker ps -a Stop a specific containerdocker stop [container name] Delete a specific containerdocker rm [container name] Display logs of a containerdocker logs [container name] Note: If you want to learn more about Dockerfiles, check out Best practices for writing Dockerfiles.7. ConclusionIn this article, we built a simple Flask app and containerized it with Docker. You can refer to this post every time you need a simple and concrete example on how to create your first Docker application. If you have any questions or feedback, feel free to ask." }, { "title": "Docker Cheetsheet üê≥", "url": "/posts/docker_cheetsheet/", "categories": "containers, docker", "tags": "docker, cheetsheet, containers", "date": "2022-02-10 18:17:00 +0530", "snippet": "Manage imagesdocker buildCreate an image from a Dockerfile.docker build [options] . -t \"app/container_name\" # name --build-arg APP_HOME=$APP_HOME # Set build-time variablesdocker runDeploys the container from docker image.docker run [options] IMAGE # see `docker create` for optionsExampleRun a command in an image.docker run -it debian:buster /bin/bashManage containersdocker Createdocker create [options] IMAGE -a, --attach # attach stdout/err -i, --interactive # attach stdin (interactive) -t, --tty # pseudo-tty --name NAME # name your image -p, --publish 5000:5000 # port map (host:container) --expose 5432 # expose a port to linked containers -P, --publish-all # publish all ports --link container:alias # linking -v, --volume `pwd`:/app # mount (absolute paths needed) -e, --env NAME=hello # env varsExampleCreate a container from an image.$ docker create --name app_redis_1 \\ --expose 6379 \\ redis:3.0.2docker ExecCommand to login to the container,docker exec [options] CONTAINER COMMAND -d, --detach # run in background -i, --interactive # stdin -t, --tty # interactiveExampleRun commands in a container.docker exec app_web_1 tail logs/development.logdocker exec -t -i app_web_1 rails cdocker start/stopStart/stop a container.docker start [options] CONTAINER -a, --attach # attach stdout/err -i, --interactive # attach stdindocker stop [options] CONTAINERdocker psManage containers using ps/kill.docker psdocker ps -adocker kill $IDdocker logsSee what‚Äôs being logged in an container.docker logs $IDdocker logs $ID 2&gt;&amp;1 | lessdocker logs -f $ID # Follow log outputImagesdocker imagesManages images.$ docker images REPOSITORY TAG ID ubuntu 12.10 b750fe78269d me/myapp latest 7b2431a8d968docker images -a # also show intermediatedocker rmiDeletes images.docker rmi b750fe78269dClean upClean allCleans up dangling images, containers, volumes, and networks (ie, not associated with a container)docker system pruneAdditionally remove any stopped containers and all unused images (not just dangling images)docker system prune -aContainers# Stop all running containersdocker stop $(docker ps -a -q)# Delete stopped containersdocker container pruneImagesDelete all the imagesdocker image prune [-a]VolumesDelete all the volumesdocker volume pruneSevicesTo view list of all the services runnning in swarmdocker service ls To see all running servicesdocker stack services stack_nameto see all services logsdocker service logs stack_name service_name To scale services quickly across qualified nodedocker service scale stack_name_service_name=replicasClean upTo clean or prune unused (dangling) imagesdocker image prune To remove all images which are not in use containers , add - adocker image prune -a To prune your entire systemdocker system prune To leave swarmdocker swarm leave To remove swarm ( deletes all volume data and database info)docker stack rm stack_name To kill all running containersdocker kill $(docekr ps -q ) Also see Getting Started (docker.io)" }, { "title": "Containerization vs. Virtualization", "url": "/posts/container_vs_virtualization/", "categories": "containers, docker", "tags": "docker, containers", "date": "2022-02-07 06:36:00 +0530", "snippet": "What‚Äôs the Difference ?container vs virtualizationContainerization and virtualization, both, are methods of deploying many isolated services on the same platform and they are both prominent tools within the hosting world. Both are a means for storing data within hosting platforms. And although both terms are becoming increasingly referenced, they are often confused.Which is the better option? That topic is frequently up for debate and is unfortunately not easily answered. The truth is that the right option depends on each user‚Äôs needs. This article will first provide a rundown of both technologies to answer this question. It discusses their uses, the situations where they perform best, and compares the advantages and disadvantages of virtualization vs containerization.Let‚Äôs understand both the concepts before diving into the differences between them.What is Virtualization ?Virtualization also refers to the process of creating many instances of operating systems on the same computer.These instances are called virtual machines. For the applications running over these virtual machines, it appears as if they are working on a system dedicated to that particular application.virtualizationVirtualization is not possible without the hypervisor. A hypervisor, or virtual machine monitor, is the software or firmware layer that enables multiple operating systems to run side-by-side, all with access to the same physical server resources. The hypervisor orchestrates and separates the available resources (computing power, memory, storage, etc.), aligning a portion to each virtual machine as needed.Examples of virtualization tools include VirtualBox, Hyper-V, VMWare Workstation Player, amongst many others.Though Virtualization also has some shortcomings. Running multiple VMs at the same time on Host OS leads to performance breakdown/degradation. The reason behind this is because the guest OS runs on the top of host OS, which will have its own kernel and dependencies, this takes up a large mass of system resources like Hard Disk, Processor and RAM.What is Containerization ?Containers are a lighter-weight, more agile way of handling virtualization ‚Äî since they don‚Äôt use a hypervisor, you can enjoy faster resource provisioning and speedier availability of new applications.Rather than spinning up an entire virtual machine, containerization packages together everything needed to run a single application or microservice (along with runtime libraries they need to run). The container includes all the code, its dependencies and even the operating system itself. This enables applications to run almost anywhere ‚Äî a desktop computer, a traditional IT infrastructure or the cloud.Containers use a form of operating system (OS) virtualization. Put simply, they leverage features of the host operating system to isolate processes and control the processes‚Äô access to CPUs, memory and desk space.Many containers share the same operating system even though they run different isolated applications.Containerization allows developers to create applications faster without having to worry about bugs when the application is run on a computing environment different than the one on which it was developed.Containerization tools include Kubernetes, Docker, Rocket, Podman etc‚Ä¶Containers vs. VMs: What are the differences?Containerization vs. VirtualizationIn traditional virtualization, a hypervisor virtualizes physical hardware. The result is that each virtual machine contains a guest OS, a virtual copy of the hardware that the OS requires to run and an application and its associated libraries and dependencies. VMs with different operating systems can be run on the same physical server. For example, a VMware VM can run next to a Linux VM, which runs next to a Microsoft VM, etc.Instead of virtualizing the underlying hardware, containers virtualize the operating system (typically Linux or Windows) so each individual container contains only the application and its libraries and dependencies. Containers are small, fast, and portable because, unlike a virtual machine, containers do not need to include a guest OS in every instance and can, instead, simply leverage the features and resources of the host OS.Which Is Better: Virtualization or Containerization?In comparing virtualization vs containerization, we see that each technology serves a different purpose. Determining the better option relies heavily on the user‚Äôs application needs and required server capacity. Virtualization and containerization are both data storage methods that create self-contained virtual packages. But, when comparing virtualization vs containerization, it will help to consider the following factors before deciding which one is right for your needs. Speed Resources Security and isolation Portability and application sharing Operating system requirements Application lifecycleChoosing one method over the other is a big decision. IT managers should consider all of the significant differences before taking the plunge. To help you decide more efficiently, we‚Äôve created a quick overview in the table below.Containerization vs. VirtualizationWrapping UpConsidering all the differences above, it is quite safe to say that containers and virtual machines can‚Äôt necessarily be used interchangeably.Each has its benefits and specific scenarios where the other does not provide practical application. It is dependent on the user as to which system works best for them in the current scenario, and then, they can choose between Containerization and Virtualization." }, { "title": "Introduction to Docker üê≥", "url": "/posts/intro-docker/", "categories": "containers, docker", "tags": "docker, docker-compose, containers", "date": "2022-01-05 18:17:00 +0530", "snippet": "In this article lets try to understand one of the most popular tools used to containerize and deploy applications i.e. Docker. It makes packaging &amp; deploying applications extremely easy.We will try to look at the things that make Docker so special and learn how you can build, deploy, and fetch applications using Docker &amp; Docker Hub using just a few steps.Docker is an open source containerization platform. It enables developers to package applications into containers‚Äîstandardized executable components combining application source code with the operating system (OS) libraries and dependencies required to run that code in any environment.Docker has been a game-changer since its release in 2013.Why use Docker?You have probably heard the iconic phrase ‚ÄúIt works on my machine‚Äù. Well, why don‚Äôt we give that machine to the customer? Improved‚Äîand seamless‚Äîportability Even lighter weight and more granular updates Automated container creation Container versioning Container reuse Shared container librariesDocker architecturearchitecture of dockerDocker uses a client-server architecture. The client talks to the Docker daemon, which does the heavy lifting of building, running, and distributing your Docker containers. The Docker client and daemon can run on the same system, or you can connect a Docker client to a remote Docker daemon. The Docker client and daemon communicate using a REST API, over UNIX sockets or a network interface. Another Docker client is Docker Compose, that lets you work with applications consisting of a set of containers.Core components of Docker Docker file Docker Image Docker Container Docker Engine Docker registryDockerfileA Dockerfile is a script that consists of a set of instructions on how to build a Docker image. These instructions include specifying the operating system, languages, environment variables, file locations, network ports, and other components needed to run the image. All the commands in the file are grouped and executed automatically.Docker Image It is a file, comprised of multiple layers, used to execute code in a Docker container. They are a set of instructions used to create docker containers.Docker ContainerIt is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings.Docker EngineThe Docker Engine (DE) is installed on the host machine and represents the core of the Docker system. It is a lightweight runtime system and the underlying client-server technology that creates and manages containers.Docker Engine consists of three components: Server - the Docker daemon (dockerd), which is responsible for creating and managing containers. Rest API - establishes communication between programs and Docker and instructs dockerd what to do. Command Line Interface (CLI) - used for running Docker commands.Docker RegistryA Docker registry is a storage and distribution system for named Docker images. The same image might have multiple different versions, identified by their tags.A Docker registry is organized into Docker repositories , where a repository holds all the versions of a specific image. The registry allows Docker users to pull images locally, as well as push new images to the registry.DockerHubDockerHub is a hosted registry solution by Docker Inc. Besides public and private repositories, it also provides automated builds, organization accounts, and integration with source control solutions like Github and Bitbucket.To Wrap Up Docker is a game-changer. But it is not a one-size-fits-all solution.Whether you like it or not, this technology has a future. There are some developers and development agencies that hate Docker and try to eliminate it from all their ongoing projects. At the same time, there are specialists who containerize everything they can because they see Docker as a panacea. Perhaps, you should not join either camp. Stay impartial, stay objective, and make a decision depending on a particular situation." }, { "title": "Common problems and solutions of TensorFlow GPU installation", "url": "/posts/tf_problems/", "categories": "deeplearning, tensorflow_error", "tags": "tensorflow, gpu", "date": "2021-01-10 10:03:00 +0530", "snippet": "When i first started using Tensorflow GPU setup, I often encounter problems. I have installed it several times and often encounter the same or similar problems. So I plan to record it and hope it can help others‚Ä¶Inconsistent Librariesgpu driver versionInitially i used to install the TensorFlow with the improper versions of CUDA &amp; Cudnn often leads me to several problems, even a slight mismatch in versions of libraries and binaries are a trouble some process to fix so i recommend everyone to follow the above chart and install the right versions on your machine.Microsoft Visual C + + 2015 redistributable update 3 is not installedIn order for the Tensorflow modules to work perfectly it needs run-time components of Visual C++ libraries. So download and install the below libraries in case u face issues.https://www.microsoft.com/en-us/download/details.aspx?id=52685Updating Environment Path to Windows (Set your PATH)After installation of CUDA and Cudnn libraries don‚Äôt forget to add its path to ensure that TensorFlow can find CUDA, you should go to the system environment and add them as mentioned below.export PATH=\"/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.0/bin:$PATH\"export PATH=\"/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.0/extras/CUPTI/libx64:$PATH\"export PATH=\"/c/tools/cuda/bin:$PATH\"system variablesCudart64 dll ErrorWhen running the tensorflow code, initially we get an error cudart64 which prevents GPU execution. I recommend you to extract the DDL script from zip and paste it to, C:\\Windows\\System32https://drive.google.com/file/d/10kKz9YRRmTtMj4vZHTt8fNrrrbgD2ooU/viewTest Tensorflow GPU installationTo verify successful installation of tensorflow, try running this in your machine and hope fully it completes without any errors.import tensorflow as tf #Device Nameprint('Device Name: '+tf.test.gpu_device_name())# Version-checkprint('Version: '+tf.__version__)#CUDA Supportprint('CUDA Support: '+str(tf.test.is_built_with_cuda()))" }, { "title": "InstaEncrypt", "url": "/posts/instacrypt/", "categories": "python, InstaEncrypt", "tags": "python, Open-Source, pypi", "date": "2020-10-30 13:25:00 +0530", "snippet": "About the ToolThis is an Open Source AES Standard encrytion tool,AES stands for Advanced Encrption Standard. It is a symmetric-key algorithm, meaning the same key is used for both encrypting and decrypting the data.aes encryptionAES encryption has three different block ciphers: AES-128 (128 bit), AES-192 (192 bit) and AES-256 (256 bit). These block ciphers are named after the key length they use for encryption and decryption. All these ciphers encrypt and decrypt the data in 128-bit blocks but they use different sizes of cryptographic keys._aes designA file (temp_key.txt) for storing the encryption key(s) for file(s)/folder(s) encrypted using the tool is automatically created in the current working directory.Always make sure to backup the encryption key if not the files cannot be reverted back‚Ä¶.!!!Built with Python 3Prerequisites Python3It is preinstalled in Ubuntu 20.04. To check the version use command :python3 --versionIf it is not preinstalled for some reason, proceed here and download as per requirement. requirements.txtRun the following command in terminal to download the required packags for running the tool locally :pip install -r requirements.txtContributing Fork the Project Create your Feature Branch (git checkout -b feature/aesEncryptionCode) Commit your Changes (git commit -m ‚ÄòAdd something‚Äô) Push to the Branch (git push origin feature/aesEncryptionCode) Open a Pull RequestFollow the given commands or use the amazing GitHub GUIHappy Contributing :)" }, { "title": "Track Model training metrics in realtime using Notifly", "url": "/posts/notifly/", "categories": "deeplearning, Notifly", "tags": "tensorflow, gpu, pypi", "date": "2020-10-17 07:35:00 +0530", "snippet": "About the packageSimple Bots to push notifications during an event trigger. wrapper to send messages, images, files over the bot using API. wrapper to send message, images, files to the channel using Webhooks. wrapper to send message, images, files to the channel using API.Built with Python 3Prerequisites PythonIt is preinstalled in Ubuntu 20.04. To check the version use command:python3 --versionIf it is not preinstalled for some reason, proceed here and download as per requirement.Run the following command in terminal to download the required packags for running the tool locally : Using requirements file :pip3 install -r requirements.txt Directly download packages:pip3 install requests==2.24.0pip3 install matplotlib==3.2.2pip3 install slackclient==2.9.3Install the packageRun the following terminal commands to install the package on the given distros. Termux:shellpkg install python3 pip3 install notifly Ubuntu/Debiansudo apt install python3-pippip3 install notifly Archsudo pacman -S python3-pippip3 install notiflyThis may take a while depending on the network speed.Working of the toolTelegramTo see how the tool works, Create the telegram bot. Getting the bot API token Search and go to _@Botfather_ . Message /mybots . Select the bot. Select the API token displayed in message. Copy and use in sample code. from notifly import telegram #import the package x = telegram.Notifier('bot API token') #create object of class Notifierx.send_message('message') #send messagex.send_image(\"image address\") #send image(.jpg or .png format)x.send_file(\"file address\") #send documentx.session_dump() #creates folder named 'downloads' in local folder, downloads/saves message,chat details for current session in 'sessio_dump.json' file Run sample code.DiscordTo see how the tool works, Create server. Create and copy server webhook and use in sample code. from notifly import discordx = discord.Notifier(r'webhook') #create object of class Notifierx.send_message('message') #send messagex.send_file(\"file address\") #send filex.send_file(\"image address\") #send image Run sample code.SlackTo see how the tool works, Create app. Follow these steps, Go here. Go to Create an App . Enter App Name and select workspace. Click Create App. Under Add features and functionality select Incoming Webhooks and Activate Incoming Webhooks. Scroll down, select Add New Webhook to Workspace and select a channel from the drop down.This channel name is used as an argument in the sample code. Click Allow. Select OAuth &amp; Permissions from left-sidebar. Under Scopes &gt; Bot Token Scopes click Add an OAuth Scope and add the following scopes,chat:write ¬† chat:write.public ¬† files:write ¬† users:write Scroll up, under OAuth Tokens for Your Team copy the Bot User OAuth Access Token to use in sample code. Click Reinstall to Workspace, select channel and click Allow. Write sample code. from notifly import slackx= slack.Notifier('token', channel='channel-name') #create object of class Notiflierx.send_message('message') #send messagex.send_file(\"image or file address\") #send image/file Run sample code.Tensorflow IntegrationPlug and play feature for your tensorflow callbacks# create your notifier using above methodsfrom notifly import discordnotifier = discord.Notifier(r'webhook') class MyNotifierCallback: @notifier.notify_on_epoch_begin(epoch_interval=1, graph_interval=1, hardware_stats_interval=1) def on_epoch_begin(self, epoch, logs=None): pass @notifier.notify_on_epoch_end(epoch_interval=1, graph_interval=1, hardware_stats_interval=1) def on_epoch_end(self, epoch, logs=None): pass @notifier.notify_on_train_begin() def on_train_begin(self, logs=None): pass @notifier.notify_on_train_end() def on_train_end(self, logs=None): passmodel.fit(callbacks=[MyNotifierCallback()])Learn more about Notifly ‚ú®Read the wiki pages which has all the above steps in great detail with some examples as well ü§©üéâ.Contributing Fork the Project Create your Feature Branch git checkout -b feature/mybranch Commit your Changes git commit -m ‚ÄòAdd something‚Äô Push to the Branch git push origin feature/mybranch Open a Pull RequestFollow the given commands or use the amazing GitHub GUIHappy Contributing" }, { "title": "TensorFlow Deep learning Setup using GPU", "url": "/posts/tf_initial_setup/", "categories": "deeplearning, tensorflow_setup", "tags": "tensorflow, gpu", "date": "2020-09-08 09:03:00 +0530", "snippet": "Deep Learning frameworksThe interest on deep-learning has been growing enormous in the past couple of months but in order to get started we need a stable development environment. I find many beginners facing problems while installing libraries and setting up environment. As i have faced first time when i was trying. So this guide is totally for beginners.Installation SetupWe will cover the following steps: Install Anaconda &amp; Python Install/ Update GPU Drivers Install CUDA Toolkit &amp; cuDNN Add Environment Variables to the PATH in Windows Install TensorFlow &amp; Keras Verify the package run(Step-1) Installation of AnacondaIn this step, kindly download the Anaconda Python package manager for your platform (Windows/Linux) and install it accordingly.https://www.anaconda.com/products/distribution(Step-2) Install GPU Drivers ‚Äî CUDA 10.1 requires 418.x or higherNow, Choose your appropriate graphics driver and install it, I recommend you to update to the latest version for better performance.nvidia driver downloadNVIDIA Drivers: https://www.nvidia.com/Download/index.aspx?lang=en-us(STEP-3) Install CUDA Toolkit ‚Äî TensorFlow supports CUDA 10.1 (TensorFlow &gt;= 2.1.0)cuda toolkit download Note: Kindly choose the CUDA version according to your Nvidia GPU version to avoid errors.Note: Kindly choose the CUDA version according to your Nvidia GPU version to avoid errors. Choose the desired platform and download it Cuda Toolkit Make sure you have the right CUDA version and drivers installed else the setup won‚Äôt work! Install CUDA Toolkit with default settings and usually it takes time so bare with it!cuda toolkit(Step-4) Adding Cudnn librariesCudnn libraries provide accelerated performance on GPU usage, so we need to add it in for smoother and efficient performance.https://developer.nvidia.com/cudnn-download-surveyIt will prompt you to create an account, go ahead and sign up and download the appropriate version for your platform.Now extract the Cudnn libraries zip file and copy all the files to ‚ÄúC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.2‚Äùlocation and overwrite the files on that location.(Step-5) Add Environment Variables to the PATH in Windows Open Run using (Win + R) and type sysdm.cpl and press Enter Under System Properties, please select the Tab Advanced. In Environment Variables go to System variables Click on Add and save the below path, Click ok and Save it. Variable name = CUDA_PATH Variable value = C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0(Step-6) Install TensorFlow &amp; KerasOpen command prompt and type in,pip install tensorflow-gpuAfter successful installation try running this below program to verify its successful setup.import tensorflow as tf# Device Nameprint('Device Name: '+tf.test.gpu_device_name()# Version-checkprint('Version: '+tf.__version__)# CUDA Supportprint('CUDA Support: '+str(tf.test.is_built_with_cuda()))cuda tf_setupIf you face any library missing issue then kindly download the below zip extract it and paste it overhttps://drive.google.com/file/d/10kKz9YRRmTtMj4vZHTt8fNrrrbgD2ooU/view?usp=sharingC:\\Windows\\System32In case u need packages and setup directly, then you can refer my Github Repohttps://github.com/rexdivakar/Deep-Learning-SetupCongratulations! üòâ You have successfully created an environment for using TensorFlow, Keras (with Tensorflow backend) over GPU on Windows!" } ]
